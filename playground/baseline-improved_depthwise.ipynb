{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *\n",
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image loading and preprocessing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crop_size = (256, 256)\n",
    "\n",
    "def preprocess_generator(generator):\n",
    "    while True:\n",
    "        batch = next(generator)\n",
    "        batch_crops = np.zeros((batch.shape[0], crop_size[0], crop_size[1], 3))\n",
    "        for i in range(batch.shape[0]):\n",
    "            batch_crops[i] = crop_img(batch[i], crop_size)\n",
    "            batch_crops[i] = (batch_crops[i] - 0.5) * 2 # shift to -1,1\n",
    "\n",
    "        assert not np.any(np.isnan(batch_crops))\n",
    "        yield batch_crops, batch_crops\n",
    "\n",
    "\n",
    "downscale_fact = 2\n",
    "image_height_orig = 720\n",
    "image_width_orig = 1280\n",
    "image_height_ds = image_height_orig // downscale_fact\n",
    "image_width_ds = image_width_orig // downscale_fact\n",
    "\n",
    "train_ds, test_ds = create_dataflows('../images', (image_height_ds, image_width_ds), 16)\n",
    "\n",
    "train_ds_prep = preprocess_generator(train_ds)\n",
    "test_ds_prep = preprocess_generator(test_ds)\n",
    "\n",
    "# train_ds_mapped = pair_mapping(train_ds)\n",
    "# test_ds_mapped = pair_mapping(test_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "images = next(train_ds_prep)\n",
    "for i, image in enumerate(images[0][:2]):\n",
    "    ax = plt.subplot(5, 1, i + 1)\n",
    "    plt.imshow(decenter_img(image))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "train_ds.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Model of the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def ssim_loss(y_true, y_pred):\n",
    "    # tf.debugging.assert_all_finite(y_true, \"Data is not finite\")\n",
    "    # tf.debugging.assert_all_finite(y_pred, \"Prediction is not finite\")\n",
    "    return 1 - tensorflow.reduce_mean(tensorflow.image.ssim_multiscale(decenter_img(y_true), decenter_img(y_pred), 1.0, filter_size=3))\n",
    "\n",
    "def ssim_mae_loss(y_true, y_pred):\n",
    "    # tf.debugging.assert_all_finite(y_true, \"Data is not finite\")\n",
    "    # tf.debugging.assert_all_finite(y_pred, \"Prediction is not finite\")\n",
    "    return ssim_loss(y_true, y_pred) * 0.5 + keras.losses.mae(y_true, y_pred) * 0.5\n",
    "\n",
    "total_variation_weight = 1e-6\n",
    "\n",
    "def tv_loss(y_true, y_pred):\n",
    "    return ssim_loss(y_true, y_pred) + total_variation_weight * tf.reduce_sum(tf.image.total_variation(decenter_img(y_pred)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from keras import backend as K, losses\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, ZeroPadding2D, BatchNormalization, Conv2DTranspose, \\\n",
    "    UpSampling2D, concatenate, DepthwiseConv2D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "def create_block(model, layers):\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=1, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(layers, kernel_size=(1, 1), strides=1, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "def create_downscale_block(model, layers):\n",
    "    model.add(DepthwiseConv2D(kernel_size=(2, 2), strides=2, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(layers, kernel_size=(1, 1), strides=1, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "def create_upscale_block(model, layers):\n",
    "    model.add(Conv2DTranspose(layers, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "def create_improved_baseline_model_12x_comp_old(image_size):\n",
    "    ### Encoder ###\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(1, 1), strides=1, kernel_initializer='he_normal',\n",
    "                     padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 32)\n",
    "    create_block(model, 32)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "    create_block(model, 64)\n",
    "    create_block(model, 64)\n",
    "    create_downscale_block(model, 64)\n",
    "\n",
    "    create_block(model, 64)\n",
    "    create_block(model, 64)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "    create_block(model, 32)\n",
    "    create_block(model, 32)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "\n",
    "    model.add(Activation('leaky_relu', name='encoded', dtype='float16'))\n",
    "\n",
    "\n",
    "    ### Decoder ###\n",
    "\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 64)\n",
    "    create_block(model, 64)\n",
    "\n",
    "    model.add(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 32)\n",
    "    create_block(model, 32)\n",
    "\n",
    "    model.add(Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 16)\n",
    "    create_block(model, 16)\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=(3, 3), strides=2, padding='same', name='decoded', kernel_initializer='he_normal', activation='tanh'))\n",
    "\n",
    "    print((\"shape of encoded\", K.int_shape(model.get_layer('encoded').output)))\n",
    "    print((\"shape of decoded\", K.int_shape(model.get_layer('decoded').output)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_improved_baseline_model_12x_comp(image_size):\n",
    "    ### Encoder ###\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(1, 1), strides=1, kernel_initializer='he_normal',\n",
    "                     padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 16)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "    create_block(model, 32)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "    create_block(model, 32)\n",
    "    create_downscale_block(model, 32)\n",
    "\n",
    "    create_block(model, 64)\n",
    "    create_downscale_block(model, 64)\n",
    "    create_block(model, 32)\n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(1, 1), strides=1, padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(Activation('leaky_relu', name='encoded', dtype='float16'))\n",
    "\n",
    "\n",
    "    ### Decoder ###\n",
    "    # model.add(UpSampling2D((2,2)))\n",
    "    create_upscale_block(model, 64)\n",
    "    create_block(model, 32)\n",
    "    # create_block(model, 32)\n",
    "\n",
    "    # model.add(UpSampling2D((2,2)))\n",
    "    create_upscale_block(model, 32)\n",
    "    # create_block(model, 32)\n",
    "    # create_block(model, 32)\n",
    "\n",
    "    create_upscale_block(model, 32)\n",
    "    # create_block(model, 32)\n",
    "\n",
    "    create_upscale_block(model, 16)\n",
    "    create_block(model, 16)\n",
    "\n",
    "    model.add(Conv2D(3, kernel_size=(1, 1), strides=1, padding='same', name='decoded', kernel_initializer='he_normal'))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    # model.add(Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # # model.add(BatchNormalization())\n",
    "    # model.add(Activation('leaky_relu'))\n",
    "    #\n",
    "    # create_block(model, 64)\n",
    "    # create_block(model, 64)\n",
    "    #\n",
    "    # model.add(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # # model.add(BatchNormalization())\n",
    "    # model.add(Activation('leaky_relu'))\n",
    "    #\n",
    "    # create_block(model, 32)\n",
    "    # create_block(model, 32)\n",
    "    #\n",
    "    # model.add(Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # # model.add(BatchNormalization())\n",
    "    # model.add(Activation('leaky_relu'))\n",
    "    #\n",
    "    # create_block(model, 16)\n",
    "    # create_block(model, 16)\n",
    "    #\n",
    "    # model.add(Conv2DTranspose(3, kernel_size=(3, 3), strides=2, padding='same', name='decoded', kernel_initializer='he_normal', activation='tanh'))\n",
    "\n",
    "    # print((\"shape of encoded\", K.int_shape(model.get_layer('encoded').output)))\n",
    "    # print((\"shape of decoded\", K.int_shape(model.get_layer('decoded').output)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_improved_baseline_model_12x_comp_new(image_size):\n",
    "    ### Encoder ###\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal',\n",
    "                     padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 16)\n",
    "    create_block(model, 16)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    create_block(model, 32)\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu', name='encoded', dtype='float16'))\n",
    "\n",
    "\n",
    "    ### Decoder ###\n",
    "\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3), strides=(1, 1), activation='tanh', padding='same', name='decoded'))\n",
    "\n",
    "    print((\"shape of encoded\", K.int_shape(model.get_layer('encoded').output)))\n",
    "    print((\"shape of decoded\", K.int_shape(model.get_layer('decoded').output)))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder = create_improved_baseline_model_12x_comp_new(crop_size)\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=ssim_loss,metrics=[ssim_loss, 'mae'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: Delete the logs before running this. The command below should do this, but I would prefer to do it manually.\n",
    "# !RMDIR \"./logs/\" /S /Q\n",
    "\n",
    "# Launching Tensorboard\n",
    "%tensorboard --logdir logs/fit --host localhost --port:6007\n",
    "# localhost:6006 in browser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, TensorBoard\n",
    "import datetime\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Set APPEND=TRUE if you are continuing the training, so that the log.csv wouldn't be reset!\n",
    "csv_logger = CSVLogger('log.csv', append=False, separator=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor = 1\n",
    "\n",
    "def train(epochs):\n",
    "    autoencoder.fit(train_ds_prep,\n",
    "                validation_data = test_ds_prep,\n",
    "                steps_per_epoch = (train_ds.n*factor) // train_ds.batch_size,\n",
    "                validation_steps = (test_ds.n*factor) // test_ds.batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=[csv_logger, tensorboard_callback],\n",
    "                verbose=1)\n",
    "\n",
    "print(\"### Pretraining:\")\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mae',metrics=[ssim_loss, 'mae'])\n",
    "train(5)\n",
    "print(\"### Training:\")\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0025), loss=ssim_loss,metrics=[ssim_loss, 'mae'])\n",
    "train(60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the model:\n",
    "# autoencoder.save('../model-saves/depthwise/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Loading the model:\n",
    "# autoencoder = keras.models.load_model('../model-saves/improved-12x-RGB-v2/', custom_objects={\n",
    "#     'ssim_loss': ssim_loss\n",
    "# })\n",
    "\n",
    "# autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "import numpy as np\n",
    "\n",
    "img_number = 4\n",
    "test_images = next(test_ds_prep)[0][:img_number]\n",
    "decoded_imgs = autoencoder.predict(test_images)\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "for i, in_img, out_img in zip(range(0, img_number, 1), test_images, decoded_imgs):\n",
    "    plt.subplot(img_number, 3, i*3+1)\n",
    "    plt.imshow(decenter_img(in_img))\n",
    "    plt.subplot(img_number, 3, i*3 + 2)\n",
    "    plt.imshow(decenter_img(out_img))\n",
    "    plt.subplot(img_number, 3, i*3 + 3)\n",
    "    rescaled_img = cv2.resize(decenter_img(in_img), (in_img.shape[0] // 3, in_img.shape[1] // 3))\n",
    "    # manual_compression = tensorflow.cast(in_img*255. ,tensorflow.int32)\n",
    "    # manual_compression = manual_compression - (manual_compression % 64)\n",
    "    # manual_compression = tensorflow.cast(manual_compression ,tensorflow.float32)\n",
    "    # manual_compression = tensorflow.cast(manual_compression/255. ,tensorflow.float32)\n",
    "    plt.imshow(rescaled_img)\n",
    "    # print(f'Image({i}) ms-ssim={ssim_loss(in_img, out_img):5.4f}, mae={np.mean(np.abs(in_img - out_img)):5.4f}, ms-ssim(manual)={ssim_loss(in_img, manual_compression):5.4f}, mae(manual)={np.mean(np.abs(in_img - manual_compression)):5.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
