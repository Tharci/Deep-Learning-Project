{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *\n",
    "from utils import *\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image loading and preprocessing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crop_size = (256, 256)\n",
    "\n",
    "def preprocess_generator_train_test(generator):\n",
    "    while True:\n",
    "        batch = next(generator)\n",
    "        batch_crops = np.zeros((batch.shape[0], crop_size[0], crop_size[1], 3))\n",
    "        for i in range(batch.shape[0]):\n",
    "            batch_crops[i] = crop_img(batch[i], crop_size)\n",
    "            batch_crops[i] = center_img(batch_crops[i]) # shift to -1,1\n",
    "        yield batch_crops, batch_crops\n",
    "\n",
    "\n",
    "def slice_img(img, slice_size):\n",
    "    padded_size = (math.ceil(img.shape[0] / float(slice_size[0])) * slice_size[0],\n",
    "                math.ceil(img.shape[1] / float(slice_size[1])) * slice_size[1],\n",
    "                img.shape[2])\n",
    "\n",
    "    padded_img = np.zeros(padded_size)\n",
    "    padded_img[0:img.shape[0], 0:img.shape[1]] = img\n",
    "    M, N = slice_size\n",
    "    slices = np.array(\n",
    "            [padded_img[x:x+M, y:y+N] for x in range(0, padded_img.shape[0], M)\n",
    "                                      for y in range(0, padded_img.shape[1], N)]\n",
    "    )\n",
    "    return slices\n",
    "\n",
    "\n",
    "def deslice_img(slices, img_size):\n",
    "    slice_size = slices[0].shape\n",
    "    img = np.zeros(img_size)\n",
    "\n",
    "    y, x = 0, 0\n",
    "    for s in slices:\n",
    "        y_to = min(y+slice_size[0], img.shape[0])\n",
    "        x_to = min(x+slice_size[1], img.shape[1])\n",
    "        img[y:y_to, x:x_to] = s[0:y_to-y, 0:x_to-x]\n",
    "        if x + slice_size[1] >= img.shape[1]:\n",
    "            x = 0\n",
    "            y += slice_size[0]\n",
    "        else:\n",
    "            x += slice_size[1]\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_generator_slice(generator):\n",
    "    while True:\n",
    "        batch = next(generator)\n",
    "        for img in batch:\n",
    "            img = center_img(img)\n",
    "            yield slice_img(img, crop_size)\n",
    "\n",
    "\n",
    "downscale_fact = 2\n",
    "image_height_orig = 720\n",
    "image_width_orig = 1280\n",
    "image_height_ds = image_height_orig // downscale_fact\n",
    "image_width_ds = image_width_orig // downscale_fact\n",
    "\n",
    "train_ds, test_ds = create_dataflows('../images', (image_height_ds, image_width_ds), 16)\n",
    "\n",
    "train_ds_prep = preprocess_generator_train_test(train_ds)\n",
    "test_ds_prep = preprocess_generator_train_test(test_ds)\n",
    "\n",
    "# train_ds_mapped = pair_mapping(train_ds)\n",
    "# test_ds_mapped = pair_mapping(test_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "images = next(train_ds_prep)\n",
    "for i, image in enumerate(images[0][:2]):\n",
    "    ax = plt.subplot(5, 1, i + 1)\n",
    "    plt.imshow(decenter_img(image))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "train_ds.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Model of the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tensorflow.reduce_mean(tensorflow.image.ssim_multiscale(decenter_img(y_true), decenter_img(y_pred), 1.0, filter_size=3))\n",
    "\n",
    "total_variation_weight = 1e-10\n",
    "\n",
    "def tv_loss(y_true, y_pred):\n",
    "    # tv = tf.reduce_sum(tf.image.total_variation(decenter_img(y_pred))) # tv1: total var of y_pred\n",
    "    # tv = tf.reduce_sum(tf.image.total_variation(tf.abs(decenter_img(y_pred) - decenter_img(y_true)))) # tv3, no high hopes, just bull\n",
    "    tv = tf.nn.relu(tf.reduce_sum(tf.image.total_variation(decenter_img(y_pred))) - tf.reduce_sum(tf.image.total_variation(decenter_img(y_true)))) # tv4\n",
    "    return ssim_loss(y_true, y_pred) + total_variation_weight * tv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from keras import backend as K, losses\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, ZeroPadding2D, BatchNormalization, Conv2DTranspose, UpSampling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "def create_improved_baseline_model_12x_comp(image_size):\n",
    "    ### Encoder ###\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(7, 7), strides=(2, 2), kernel_initializer='he_normal',\n",
    "                     padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('leaky_relu', name='encoded', dtype='float16'))\n",
    "\n",
    "\n",
    "    ### Decoder ###\n",
    "\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization()) #\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    # model.add(Conv2DTranspose(32, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')) #\n",
    "    # model.add(BatchNormalization()) #\n",
    "    # model.add(Activation('leaky_relu')) #\n",
    "\n",
    "    model.add(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization()) #\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    # model.add(Conv2DTranspose(16, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')) #\n",
    "    # model.add(BatchNormalization()) #\n",
    "    # model.add(Activation('leaky_relu')) #\n",
    "\n",
    "    # model.add(Conv2DTranspose(16, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')) #\n",
    "    # model.add(BatchNormalization()) #\n",
    "    # model.add(Activation('leaky_relu')) #\n",
    "\n",
    "    model.add(Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization()) #\n",
    "    model.add(Activation('leaky_relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=(7, 7), strides=(2, 2), activation='tanh', padding='same', name='decoded'))\n",
    "\n",
    "    print((\"shape of encoded\", K.int_shape(model.get_layer('encoded').output)))\n",
    "    print((\"shape of decoded\", K.int_shape(model.get_layer('decoded').output)))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder = create_improved_baseline_model_12x_comp(crop_size)\n",
    "# autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0025), loss=ssim_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: Delete the logs before running this. The command below should do this, but I would prefer to do it manually.\n",
    "# !RMDIR \"./logs/\" /S /Q\n",
    "\n",
    "# Launching Tensorboard\n",
    "%tensorboard --logdir ./logs/fit --host localhost #--port:6006\n",
    "# localhost:6006 in browser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, TensorBoard\n",
    "import datetime\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Set APPEND=TRUE if you are continuing the training, so that the log.csv wouldn't be reset!\n",
    "csv_logger = CSVLogger('log.csv', append=False, separator=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.fit(train_ds_prep,\n",
    "                validation_data = test_ds_prep,\n",
    "                steps_per_epoch = train_ds.n // train_ds.batch_size,\n",
    "                validation_steps = test_ds.n // test_ds.batch_size,\n",
    "                epochs=5,\n",
    "                callbacks=[csv_logger, tensorboard_callback],\n",
    "                verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the model:\n",
    "# autoencoder.save('../model-saves/TV-TEST/tv_loss_4/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the model:\n",
    "# autoencoder = keras.models.load_model('../model-saves/improved-12x-RGB-v2/', custom_objects={\n",
    "#     'ssim_loss': ssim_loss\n",
    "# })\n",
    "\n",
    "# autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running the AutoEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "img_number = 16\n",
    "display_img_number = 4\n",
    "\n",
    "test_set = []\n",
    "for i in range(img_number):\n",
    "    test_set.append(next(preprocess_generator_slice(test_ds)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_size = (image_height_ds, image_width_ds, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "\n",
    "ssim_values = []\n",
    "for i in range(img_number):\n",
    "    image_slices = test_set[i]\n",
    "\n",
    "    decoded_slices = autoencoder.predict(image_slices)\n",
    "    decoded_img = deslice_img(decoded_slices, img_size)\n",
    "    decoded_img = decenter_img(decoded_img)\n",
    "\n",
    "    original_image = decenter_img(deslice_img(image_slices, img_size))\n",
    "\n",
    "    ssim = 1 - tensorflow.image.ssim_multiscale(original_image, decoded_img, 1.0, filter_size=3)\n",
    "    ssim_values.append(ssim)\n",
    "    print(ssim.numpy())\n",
    "\n",
    "    if i < display_img_number:\n",
    "        plt.subplot(display_img_number, 2, i*2+1)\n",
    "        plt.imshow(original_image)\n",
    "        plt.subplot(display_img_number, 2, i*2+2)\n",
    "        plt.imshow(decoded_img)\n",
    "\n",
    "print(\"AVERAGE SSIM: \")\n",
    "print(np.array(ssim_values).mean())\n",
    "\n",
    "# rescaled_img = cv2.resize(decenter_img(in_img), (in_img.shape[0] // 3, in_img.shape[1] // 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
